Iulia Ispas
During the second lab session of our AR project, our team focused on building the user interface (UI) for our tabletop solar system. The overall goal of the project is to allow the user to see the planets orbiting the sun, and when selecting one, the chosen planet should be displayed in more detail, visually enlarged on the left side of the screen, with additional information shown in a text panel on the right.
Our focus this session was to design and implement the Canvas system that would handle this interaction and display layout. We started by setting up the Canvas in Unity, which serves as the main container for all UI elements. Initially, our plan was quite ambitious: we wanted the selected planet to smoothly spin and scale up while moving into position on the left side of the screen. Simultaneously, an information panel would appear on the right, displaying data such as the planet’s size, density, orbital period, and a fun fact. This approach aimed to create a dynamic and engaging transition, combining both visual appeal and educational value.
However, as we started implementing the animation logic, we quickly ran into several problems. Combining a rotating 3D object with the UI Canvas was more complicated than expected. The rotation often behaved unexpectedly, sometimes spinning off-axis or appearing distorted when scaled up. Additionally, integrating a 3D object with Unity’s Canvas system proved tricky, especially when working in Screen Space Overlay mode. Despite trying several configurations, the animation didn’t behave as intended and created visual inconsistencies, particularly when combined with UI layout components.
After some time experimenting, we decided to simplify our approach. Instead of animating the transition, we switched to directly displaying the selected planet in a fixed position on the left side of the screen. The corresponding textual information would appear on the right, within a neatly designed panel. This made the experience more stable and predictable, allowing us to focus on clarity and usability rather than complex animations that didn’t add significant value to the user.
We chose to keep the Canvas in Screen Space – Overlay mode. This render mode means the Canvas is drawn directly on top of the screen, making it ideal for consistent 2D UI that stays fixed in place regardless of the 3D camera movement. In our AR setup, this approach ensures that the text and planet preview are always clearly visible to the user, independent of where the camera or AR tracking system moves. It also simplifies layering and interaction with buttons or other UI elements, since they always remain in the same visual plane.
Before settling on Screen Space Overlay, we experimented with World Space render mode. At first, we thought this was the correct approach since it allows UI elements to exist physically within the 3D world. However, we realized that World Space canvases are more suitable for in-world interfaces, like placing a floating control panel next to an AR object or attaching labels to 3D elements in space. That mode makes sense when the UI needs to behave as part of the AR environment and respond to perspective and depth. In our case, we wanted a consistent and readable information panel that would always appear in front of the user, not move around the table or depend on viewing angle. Therefore, Screen Space Overlay was the right choice.
Once the rendering mode issue was settled, we discovered that by placing all the planet models inside the Main Camera (inside the XR Origin) and properly adjusting their positions, they became visible within the Canvas. This setup allowed us to blend 3D planets with UI elements, achieving the hybrid layout we wanted: an informative panel with a realistic 3D visual next to it.
Next, we focused on structuring the Panel that would hold the planet information. We created a large rectangular panel that would take roughly one-third/one-fourth of the screen on the right side. Inside the panel, we added multiple TextMeshPro text fields to hold the information we wanted to display. To organize these text elements, we grouped them under an empty GameObject and attached a Vertical Layout Group to it. This layout component automatically stacks all text elements vertically, maintaining even spacing and padding between them. 
We also spent time on the visual design of the UI. We wanted the panel to be readable but still feel integrated with the AR environment, so we used a semi-transparent background (black with alpha value around 150) to maintain readability while letting the user still see a bit of the AR background through it. 
The rest of the lab time was spent researching what kind of information we wanted to display for each planet. We collected data such as diameter, density, orbital period, day length, and short descriptions with interesting fun facts. This information will later be integrated into our script, which should dynamically update the panel based on the planet the user selects.
By the end of this lab session, we had a UI foundation for our AR solar system. Even though our initial idea of animating planets didn’t work as expected, we learned a lot about UI rendering modes, layout systems, and how to integrate 3D content into a 2D overlay. Overall, the session was productive, even if we didn’t do as much as we planned, it helped us transform our conceptual design into a UI structure and better understand the balance between creativity and practicality in AR interface design.

